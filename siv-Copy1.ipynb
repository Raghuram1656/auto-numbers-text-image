{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dd1d7c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)  # This notebook runs on TensorFlow 1.15.x or earlier\n",
    "tf_framework_version = tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2bbe420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import Session\n",
    "role = get_execution_role()\n",
    "sess = Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "#from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fe71c794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:2424: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "pr = ktrain.load_predictor('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1b707367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Z7'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.predict('Data to test Infosys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "52847fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1e0fedc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "# loading preprocess and model file\n",
    "features = pickle.load(open('saved/tf_model.preproc',\n",
    "                            'rb'))\n",
    "loaded_model = load_model('saved/tf_model.h5')\n",
    "labels = ['Z7', 'Z9A','Z9B', 'Z9C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e13082d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7f2045685d30>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features;loaded_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "34e044e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import builder as builder\n",
    "from tensorflow.python.saved_model.signature_def_utils import predict_signature_def\n",
    "from tensorflow.python.saved_model import tag_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7129a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.executing_eagerly():\n",
    "    tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fecc6166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'export/Servo/1/saved_model.pb'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: This directory structure will need to be followed \n",
    "model_version = '1'\n",
    "export_dir = 'export/Servo/' + model_version\n",
    "\n",
    "\n",
    "# Build the Protocol Buffer SavedModel at 'export_dir'\n",
    "builder = builder.SavedModelBuilder(export_dir)\n",
    "\n",
    "# Create prediction signature to be used by TensorFlow Serving Predict API\n",
    "signature = predict_signature_def(\n",
    "   inputs={\"inputs\": loaded_model.input}, outputs={\"score\": loaded_model.output})\n",
    "\n",
    "session = tf.compat.v1.Session()\n",
    "init_op = tf.compat.v1.global_variables_initializer()\n",
    "session.run(init_op)\n",
    "# Save the meta graph and variables\n",
    "builder.add_meta_graph_and_variables(\n",
    "    sess=session, tags=[tag_constants.SERVING], signature_def_map={\"serving_default\": signature})\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "211ba2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['serving_default']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['inputs'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 512)\r\n",
      "        name: input_1_1:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['score'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 4)\r\n",
      "        name: activation_1/Softmax:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "model_path = 'export/Servo/1/'\n",
    "#model_path = \n",
    "!saved_model_cli show --all --dir {model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "76a4d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "model_archive = 'model.tar.gz'\n",
    "with tarfile.open(model_archive, mode='w:gz') as archive:\n",
    "    archive.add('export', recursive=True) \n",
    "\n",
    "# upload model artifacts to S3\n",
    "model_data = sess.upload_data(path=model_archive, key_prefix='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bb75d7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-1-139008155365/model/model.tar.gz'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "39e66edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.serving import Model\n",
    "instance_type = 'ml.c5.xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3131df11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class sagemaker.tensorflow.serving.Model has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "sm_model1 = Model(model_data=model_data, framework_version=tf_framework_version,role=role)\n",
    "uncompiled_predictor_siv = sm_model1.deploy(initial_instance_count=1, instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "95925269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.tensorflow.model.TensorFlowPredictor object at 0x7f1e347203c8>\n"
     ]
    }
   ],
   "source": [
    "print(uncompiled_predictor_siv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9fb1aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"KELLY SERVICES Title:Â DocumentÂ administrator TheÂ DocumentÂ administrator is theÂ associateÂ responsible for perform the technical (format) check of theÂ documents and its promotion to the Data Integrity or Final state depending on theÂ documentÂ type. Key responsibilities: - Checking all properties of theÂ documentÂ for accuracy with system properties , including eCTD filenames. - Responsible to support the DD&C (Device Development & Commercialization) team people with system issues, doubts providing clarification and resolution. - Checking theÂ documentfor compliance with IRDDS standards (International Research & DevelopmentÂ DocumentÂ Standards) and Novstyle, as appropriate. - Promote or demoteÂ documentÂ in lifecycle, promote for Data integrity check and or Approve as defined by SOP , demote to create (author possession for update). - Change ownership ofÂ documents depending of the doc. lifecycle status. - Execute manual retirement of doc. old versions, upon request from user and monthly by taking a list from system - Maintain a tracker of activities executed by DA - Responsible for support the DD&C team as record coordinator (paper archiving). - Responsible for support the DD&C team shipping packages true DHL and others Language: Excellent skills in English language are required. Professional Experience: The successful candidate for this position will have strong experience with office word and excel applications. Must: Experience/knowledge in: - TEDI System or aÂ Documentum system like Subway - IRDDS Good to have: Experience with Novstyle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3f8c8485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:1: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "data = np.fromstring(data, dtype=np.uint8,count=-1, sep='')\n",
    "data = np.resize(1,512)\n",
    "predictions = uncompiled_predictor_siv.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "44118b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "829d93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncompiled_predictor_siv.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b567a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
